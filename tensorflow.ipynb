{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-1.2.0rc2-cp36-cp36m-win_amd64.whl (21.2MB)\n",
      "Collecting backports.weakref==1.0rc1 (from tensorflow)\n",
      "  Downloading backports.weakref-1.0rc1-py3-none-any.whl\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\users\\joshua.chen\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from tensorflow)\n",
      "Requirement already satisfied: numpy>=1.11.0 in c:\\users\\joshua.chen\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from tensorflow)\n",
      "Collecting protobuf>=3.2.0 (from tensorflow)\n",
      "  Downloading protobuf-3.3.0.tar.gz (271kB)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\joshua.chen\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from tensorflow)\n",
      "Collecting html5lib==0.9999999 (from tensorflow)\n",
      "  Downloading html5lib-0.9999999.tar.gz (889kB)\n",
      "Requirement already satisfied: werkzeug>=0.11.10 in c:\\users\\joshua.chen\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from tensorflow)\n",
      "Requirement already satisfied: bleach==1.5.0 in c:\\users\\joshua.chen\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from tensorflow)\n",
      "Collecting markdown==2.2.0 (from tensorflow)\n",
      "  Downloading Markdown-2.2.0.tar.gz (236kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\joshua.chen\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages\\setuptools-27.2.0-py3.6.egg (from protobuf>=3.2.0->tensorflow)\n",
      "Building wheels for collected packages: protobuf, html5lib, markdown\n",
      "  Running setup.py bdist_wheel for protobuf: started\n",
      "  Running setup.py bdist_wheel for protobuf: finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\joshua.chen\\AppData\\Local\\pip\\Cache\\wheels\\1b\\42\\a0\\4c7343df5b629ec9c75655468dce7652b28026896b0209ba55\n",
      "  Running setup.py bdist_wheel for html5lib: started\n",
      "  Running setup.py bdist_wheel for html5lib: finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\joshua.chen\\AppData\\Local\\pip\\Cache\\wheels\\6f\\85\\6c\\56b8e1292c6214c4eb73b9dda50f53e8e977bf65989373c962\n",
      "  Running setup.py bdist_wheel for markdown: started\n",
      "  Running setup.py bdist_wheel for markdown: finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\joshua.chen\\AppData\\Local\\pip\\Cache\\wheels\\b9\\4f\\6c\\f4c1c5207c1d0eeaaf7005f7f736620c6ded6617c9d9b94096\n",
      "Successfully built protobuf html5lib markdown\n",
      "Installing collected packages: backports.weakref, protobuf, html5lib, markdown, tensorflow\n",
      "  Found existing installation: html5lib 0.999\n",
      "    Uninstalling html5lib-0.999:\n",
      "      Successfully uninstalled html5lib-0.999\n",
      "Successfully installed backports.weakref-1.0rc1 html5lib-0.9999999 markdown-2.2.0 protobuf-3.3.0 tensorflow-1.2.0rc2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    DEPRECATION: Uninstalling a distutils installed project (html5lib) has been deprecated and will be removed in a future version. This is due to the fact that uninstalling a distutils project will only partially uninstall the project.\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf core tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_34:0\", shape=(), dtype=float32) Tensor(\"Const_35:0\", shape=(), dtype=float32)\n",
      "[3.0, 4.0]\n",
      "node3 is : Tensor(\"Add_13:0\", shape=(), dtype=float32)\n",
      "sess.run(node3):  7.0\n",
      "7.5\n",
      "[ 3.  7.]\n",
      "421.875\n",
      "[ 0.          0.30000001  0.60000002  0.90000004]\n",
      "23.66\n",
      "[array([-1.], dtype=float32), array([ 1.], dtype=float32)]\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "node1 = tf.constant(3.0, dtype=tf.float32)\n",
    "node2 = tf.constant(4.0) # also tf.float32 implicitly\n",
    "#並沒有如想像的印出 3.0,4.0，只有當賦值(evaluate)後才會出現3.0,4.0\n",
    "print(node1, node2)\n",
    "#Tensor(\"Const:0\", shape=(), dtype=float32) Tensor(\"Const_1:0\", shape=(), dtype=float32)\n",
    "#session include control and state of tf runtime\n",
    "sess = tf.Session()\n",
    "print(sess.run([node1, node2]))\n",
    "#operaton is also node\n",
    "node3 = tf.add(node1,node2)\n",
    "print(\"node3 is :\",node3)\n",
    "print(\"sess.run(node3): \",sess.run(node3))\n",
    "#placeholder 一開始沒有值，只有當計算時才會給值進去\n",
    "a = tf.placeholder(tf.float32)\n",
    "b = tf.placeholder(tf.float32)\n",
    "#有點類似lambda概念\n",
    "# + provides a shortcut for tf.add(a, b)\n",
    "adder_node = a+b\n",
    "print(sess.run(adder_node, {a: 3, b:4.5}))\n",
    "print(sess.run(adder_node, {a: [1,3], b: [2, 4]}))\n",
    "#可以一層層疊上去，這樣的設計是因為希望在ML的model裡能夠take arbitrary(任意的) inputs\n",
    "add_and_triple = adder_node ** 3\n",
    "print(sess.run(add_and_triple, {a: 3, b:4.5}))\n",
    "#Variables讓我們能夠在訓練模型下，持續調整參數，讓我們達到相同inputs但卻有不同的outputs\n",
    "W = tf.Variable([.3], dtype=tf.float32)\n",
    "b = tf.Variable([-.3], dtype=tf.float32)\n",
    "x = tf.placeholder(tf.float32)\n",
    "linear_model = W * x + b\n",
    "#與constant不同的是，constant一開始就被初始化了，Variables並沒有，所以要呼叫一個initialize function\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "#賦值時一定要是dict型別\n",
    "print(sess.run(linear_model,{x:[1,2,3,4]}))\n",
    "#為了評估模型的正確性，需要一個y placeholder\n",
    "y = tf.placeholder(tf.float32)\n",
    "squared_deltas = tf.square(linear_model - y)\n",
    "#加總所有的誤差平方\n",
    "loss = tf.reduce_sum(squared_deltas)\n",
    "print(sess.run(loss, {x:[1,2,3,4], y:[0,-1,-2,-3]}))\n",
    "#從新指派新的值給W,b\n",
    "fixW = tf.assign(W, [-1.])\n",
    "fixb = tf.assign(b, [1.])\n",
    "sess.run([fixW, fixb])\n",
    "print(sess.run(loss, {x:[1,2,3,4], y:[0,-1,-2,-3]}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train.api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([-0.9999969], dtype=float32), array([ 0.99999082], dtype=float32)]\n",
      "W: [-0.9999969] b: [ 0.99999082] loss: 5.69997e-11\n"
     ]
    }
   ],
   "source": [
    "#這邊使用gradient decent方法來最小化loss function\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "train = optimizer.minimize(loss)\n",
    "sess.run(init) # reset values to incorrect defaults. 若不初始化會得到剛被指派的變數W=-1,b=1\n",
    "#x:[1,2,3,4],y:[0,-1,-2,-3]is training data\n",
    "for i in range(1000):\n",
    "    sess.run(train, {x:[1,2,3,4], y:[0,-1,-2,-3]})\n",
    "\n",
    "print(sess.run([W, b]))\n",
    "curr_W, curr_b, curr_loss = sess.run([W, b, loss], {x:[1,2,3,4], y:[0,-1,-2,-3]})\n",
    "print(\"W: %s b: %s loss: %s\"%(curr_W, curr_b, curr_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.contrib.learn ==> high-level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\JOSHUA~1.CHE\\AppData\\Local\\Temp\\tmp3gnm5m0m\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x00000269B6DCDDD8>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': 'C:\\\\Users\\\\JOSHUA~1.CHE\\\\AppData\\\\Local\\\\Temp\\\\tmp3gnm5m0m'}\n",
      "WARNING:tensorflow:From C:\\Users\\joshua.chen\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\JOSHUA~1.CHE\\AppData\\Local\\Temp\\tmp3gnm5m0m\\model.ckpt.\n",
      "INFO:tensorflow:loss = 1.25, step = 1\n",
      "INFO:tensorflow:global_step/sec: 847.44\n",
      "INFO:tensorflow:loss = 0.0330949, step = 101 (0.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 862.094\n",
      "INFO:tensorflow:loss = 0.00545467, step = 201 (0.110 sec)\n",
      "INFO:tensorflow:global_step/sec: 868.98\n",
      "INFO:tensorflow:loss = 0.000224949, step = 301 (0.115 sec)\n",
      "INFO:tensorflow:global_step/sec: 877.181\n",
      "INFO:tensorflow:loss = 0.000118668, step = 401 (0.112 sec)\n",
      "INFO:tensorflow:global_step/sec: 952.357\n",
      "INFO:tensorflow:loss = 1.1998e-05, step = 501 (0.108 sec)\n",
      "INFO:tensorflow:global_step/sec: 999.979\n",
      "INFO:tensorflow:loss = 3.35462e-06, step = 601 (0.099 sec)\n",
      "INFO:tensorflow:global_step/sec: 934.549\n",
      "INFO:tensorflow:loss = 5.77568e-07, step = 701 (0.107 sec)\n",
      "INFO:tensorflow:global_step/sec: 952.374\n",
      "INFO:tensorflow:loss = 7.43297e-08, step = 801 (0.104 sec)\n",
      "INFO:tensorflow:global_step/sec: 1190.44\n",
      "INFO:tensorflow:loss = 8.6177e-09, step = 901 (0.084 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into C:\\Users\\JOSHUA~1.CHE\\AppData\\Local\\Temp\\tmp3gnm5m0m\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 1.19821e-09.\n",
      "WARNING:tensorflow:From C:\\Users\\joshua.chen\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Starting evaluation at 2017-08-16-03:16:08\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\JOSHUA~1.CHE\\AppData\\Local\\Temp\\tmp3gnm5m0m\\model.ckpt-1000\n",
      "INFO:tensorflow:Finished evaluation at 2017-08-16-03:16:09\n",
      "INFO:tensorflow:Saving dict for global step 1000: global_step = 1000, loss = 1.31667e-09\n",
      "WARNING:tensorflow:From C:\\Users\\joshua.chen\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Starting evaluation at 2017-08-16-03:16:09\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\JOSHUA~1.CHE\\AppData\\Local\\Temp\\tmp3gnm5m0m\\model.ckpt-1000\n",
      "INFO:tensorflow:Finished evaluation at 2017-08-16-03:16:10\n",
      "INFO:tensorflow:Saving dict for global step 1000: global_step = 1000, loss = 0.00252726\n",
      "train loss: {'loss': 1.3166699e-09, 'global_step': 1000}\n",
      "eval loss: {'loss': 0.0025272602, 'global_step': 1000}\n"
     ]
    }
   ],
   "source": [
    "#1.running training loops\n",
    "#2.running evaluation loops\n",
    "#3.managing data sets\n",
    "#4.managing feeding\n",
    "features = [tf.contrib.layers.real_valued_column(\"x\", dimension=1)]\n",
    "estimator = tf.contrib.learn.LinearRegressor(feature_columns=features)\n",
    "x_train = np.array([1., 2., 3., 4.])\n",
    "y_train = np.array([0., -1., -2., -3.])\n",
    "x_eval = np.array([2., 5., 8., 1.])\n",
    "y_eval = np.array([-1.01, -4.1, -7, 0.])\n",
    "input_fn = tf.contrib.learn.io.numpy_input_fn({\"x\":x_train}, y_train,batch_size=4,num_epochs=1000)\n",
    "eval_input_fn = tf.contrib.learn.io.numpy_input_fn({\"x\":x_eval}, y_eval, batch_size=4, num_epochs=1000)\n",
    "estimator.fit(input_fn=input_fn, steps=1000)\n",
    "train_loss = estimator.evaluate(input_fn=input_fn)\n",
    "eval_loss = estimator.evaluate(input_fn=eval_input_fn)\n",
    "print(\"train loss: %r\"% train_loss)\n",
    "print(\"eval loss: %r\"% eval_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#custom model\n",
    "#use tf.contrib.learn.Estimator \n",
    "#tf.contrib.learn.LinearRegressor is a sub-class of tf.contrib.learn.Estimator\n",
    "def model(features, labels, mode):\n",
    "    # Build a linear model and predict values\n",
    "    W = tf.get_variable(\"W\", [1], dtype=tf.float64)\n",
    "    b = tf.get_variable(\"b\", [1], dtype=tf.float64)\n",
    "    y = W*features['x'] + b\n",
    "    # Loss sub-graph\n",
    "    loss = tf.reduce_sum(tf.square(y - labels))\n",
    "    # Training sub-graph\n",
    "    global_step = tf.train.get_global_step()\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "    train = tf.group(optimizer.minimize(loss),\n",
    "                   tf.assign_add(global_step, 1))\n",
    "    # ModelFnOps connects subgraphs we built to the\n",
    "    # appropriate functionality.\n",
    "    return tf.contrib.learn.ModelFnOps(\n",
    "      mode=mode, predictions=y,\n",
    "      loss=loss,\n",
    "      train_op=train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 下載MNIST資料集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.contrib.learn.python.learn.datasets.base.Datasets'>\n",
      "55000\n",
      "5000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print (type(mnist))\n",
    "print (mnist.train.num_examples)\n",
    "print (mnist.validation.num_examples)\n",
    "print (mnist.test.num_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train_img 的 type : <class 'numpy.ndarray'>\n",
      " train_img 的 dimension : (55000, 784)\n",
      " train_label 的 type : [[ 0.  0.  0. ...,  1.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  1.  0.]]\n",
      " train_label 的 dimension : (55000, 10)\n",
      " test_img 的 type : <class 'numpy.ndarray'>\n",
      " test_img 的 dimension : (10000, 784)\n",
      " test_label 的 type : <class 'numpy.ndarray'>\n",
      " test_label 的 dimension : (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "train_img = mnist.train.images\n",
    "train_label = mnist.train.labels\n",
    "test_img = mnist.test.images\n",
    "test_label = mnist.test.labels\n",
    "#image的shape為784，因為是28*28像素，label的shape是10代表0~9\n",
    "print(\" train_img 的 type : {}\" .format(type(train_img)))\n",
    "#train_img每張圖的格式為(1,784)\n",
    "print(\" train_img 的 dimension : {}\" .format(train_img.shape))\n",
    "print(\" train_label 的 type : %s\" % (train_label))\n",
    "print(\" train_label 的 dimension : %s\" % (train_label.shape,))\n",
    "print(\" test_img 的 type : %s\" % (type(test_img)))\n",
    "print(\" test_img 的 dimension : %s\" % (test_img.shape,))\n",
    "print(\" test_label 的 type : %s\" % (type(test_label)))\n",
    "print(\" test_label 的 dimension : %s\" % (test_label.shape,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQQAAAEMCAYAAAAiW8hnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ntR/Yo5VKZQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x269b6742f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQQAAAEMCAYAAAAiW8hnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYGaJA8HMkv8H5d3ZPKdca1sAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x269b67d0898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQQAAAEMCAYAAAAiW8hnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x269b68330f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#查看圖片長的樣子\n",
    "nsample = 1\n",
    "randidx = np.random.randint(train_img.shape[0], size=nsample)\n",
    "for i in [0, 1, 2]:\n",
    "    #i是代表第幾張圖\n",
    "    curr_img   = np.reshape(train_img[i, :], (28, 28)) # 28 by 28 matrix \n",
    "    #curr_label是該圖的標籤，train_label的形式為[0,0,0,1,0,0,0,0,0,0]，argmax可以找到該list中最大值的index所以是3\n",
    "    curr_label = np.argmax(train_label[i, :] ) # Label\n",
    "    plt.matshow(curr_img, cmap=plt.get_cmap('gray'))\n",
    "    plt.title(\"\" + str(i + 1) + \"th Training Data \" \n",
    "              + \"Label is \" + str(curr_label))\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8851\n",
      "(7, 7)\n",
      "(2, 2)\n",
      "(1, 1)\n",
      "(0, 0)\n",
      "(4, 4)\n",
      "(1, 1)\n",
      "(4, 4)\n",
      "(9, 9)\n",
      "(6, 5)\n",
      "(9, 9)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "#y是預測的資料\n",
    "y = tf.matmul(x, W) + b\n",
    "\n",
    "#為了訓練模型，需要告訴model哪種結果是好的，壞的結果以cost、loss function\n",
    "#此處使用cross-entropy方式來定義loss\n",
    "y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "#cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))\n",
    "#softmax_cross_entropy_with_logits logits參數是預測資料，labels是實際資料\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits = y,labels = y_)\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "#隨機取mnist的100筆資料來訓練\n",
    "for i in range(1000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    sess.run(train_step, {x: batch_xs, y_: batch_ys})\n",
    "# print(x[1])    \n",
    "# for i in [0,1,2]:\n",
    "#     curr_img   = np.reshape(x[i, :], (28, 28))\n",
    "#     curr_label = np.argmax(y[i, :] ) # Label\n",
    "#     plt.matshow(curr_img, cmap=plt.get_cmap('gray'))\n",
    "#     plt.title(\"\" + str(i + 1) + \"th Training Data \" \n",
    "#               + \"Label is \" + str(curr_label))\n",
    "#print boolean for each equation    \n",
    "#y是預測的結果，y_是實際結果\n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "#print出準確度\n",
    "print(sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels}))\n",
    "#print預測結果和實際結果\n",
    "for i in range(10):\n",
    "    print(sess.run((tf.argmax(y[i,:]),tf.argmax(y_[i,:])),feed_dict={x: mnist.test.images, y_: mnist.test.labels}))\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# improving the accuracy for MNIST by CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.2\n"
     ]
    }
   ],
   "source": [
    "#numpy的矩陣運算會以python以外的語言運算(高效)，但每次運算都要轉換成別種語言會有很多overhead(額外支出)，尤其是在GPU和分散式架構上\n",
    "#tf也是以python以外的預言來運算，但是是一次運算一個階段，所以可減少overhead，類似描述一個tf的流程圖\n",
    "import tensorflow as tf\n",
    "sess = tf.InteractiveSession()\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding = 'SAME')\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding = 'SAME')\n",
    "W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "b_conv1 = bias_variable([32])\n",
    "x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "W_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7 * 7 * 64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "#dropout\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "\n",
    "y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n",
    "\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = y_conv, labels = y_))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "sess.run(tf.global_variables_initializer())\n",
    "#跑20000次才夠\n",
    "for i in range(200):\n",
    "    batch = mnist.train.next_batch(50)\n",
    "    if i%100 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={\n",
    "        x:batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "        print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "    train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
    "\n",
    "print(\"test accuracy %g\"%accuracy.eval(feed_dict={\n",
    "    x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
